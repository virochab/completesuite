from deepeval.test_case import Turn
from deepeval.simulator import ConversationSimulator
from deepeval.dataset import ConversationalGolden
from deepeval.test_case import ConversationalTestCase
import sys
from pathlib import Path
import json
from datetime import datetime
import os

# Add parent directory to Python path to enable imports
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# Import the weather app callback
from utils.wrapRAGModelForSyntheticData import model_callback

# Example RAG-related ConversationalGolden (from multiturn_goldens)
conversation_golden = ConversationalGolden(
    scenario="A geography teacher leads a classroom discussion on the impact of dams, but students must also consider recent local flooding caused by heavy rains and debate how dam construction both helps manage floods and creates new challenges for displaced communities and river pollution, while proposing region-specific solutions for water conservation and river cleanliness.",
    expected_outcome="Students understand the benefits and drawbacks of dam construction, discuss the relationship between dams and flood management, recognize challenges faced by displaced communities and river pollution, and propose practical, local solutions for water conservation and river cleanliness.",
    user_description="Student studying science, geography, and environmental studies in class",
)

# Alternative: Load conversational goldens from generated JSON file
def load_conversational_goldens_from_json(json_path: str):
    """
    Load ConversationalGolden objects from a JSON file generated by the synthesizer.
    
    Args:
        json_path: Path to the JSON file containing conversational goldens
    
    Returns:
        List of ConversationalGolden objects
    """
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    goldens = []
    for item in data:
        golden = ConversationalGolden(
            scenario=item.get('scenario', ''),
            expected_outcome=item.get('expected_outcome', ''),
            user_description=item.get('user_description'),
            context=item.get('context', []),
        )
        goldens.append(golden)
    
    return goldens

def save_conversational_test_cases_to_json(test_cases, output_dir: str, filename_prefix: str = "conversational_test_cases"):
    """
    Save ConversationalTestCase objects to a JSON file.
    
    Args:
        test_cases: List of ConversationalTestCase objects
        output_dir: Directory where to save the JSON file
        filename_prefix: Prefix for the filename
    
    Returns:
        Path to the saved JSON file
    """
    # Create directory if it doesn't exist
    os.makedirs(output_dir, exist_ok=True)
    
    # Convert test cases to dictionaries
    test_cases_data = []
    for test_case in test_cases:
        test_case_dict = {
            "turns": [
                {
                    "role": turn.role,
                    "content": turn.content
                }
                for turn in test_case.turns
            ]
        }
        
        # Add additional attributes if they exist
        if hasattr(test_case, 'scenario'):
            test_case_dict["scenario"] = test_case.scenario
        if hasattr(test_case, 'expected_outcome'):
            test_case_dict["expected_outcome"] = test_case.expected_outcome
        if hasattr(test_case, 'user_description'):
            test_case_dict["user_description"] = test_case.user_description
        if hasattr(test_case, 'context'):
            test_case_dict["context"] = test_case.context
        
        test_cases_data.append(test_case_dict)
    
    # Create filename with timestamp
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"{filename_prefix}_{timestamp}.json"
    filepath = os.path.join(output_dir, filename)
    
    # Save to JSON file
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(test_cases_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… Saved {len(test_cases)} conversational test cases to: {filepath}")
    return filepath

# Run Simulation with weather app callback
simulator = ConversationSimulator(model_callback=model_callback)

# Option 1: Use the example golden
print("=== Simulating conversation with example RAG scenario ===")
conversational_test_cases = simulator.simulate(conversational_goldens=[conversation_golden])
print(f"\nGenerated {len(conversational_test_cases)} conversational test cases:")
for i, test_case in enumerate(conversational_test_cases, 1):
    print(f"\n--- Test Case {i} ---")
    print(f"Turns: {len(test_case.turns)}")
    for j, turn in enumerate(test_case.turns, 1):
        print(f"  Turn {j} ({turn.role}): {turn.content[:100]}..." if len(turn.content) > 100 else f"  Turn {j} ({turn.role}): {turn.content}")

# Save generated conversations to JSON
# Save to: synthetic_data/multiturn/conversationalTestcases
output_dir = project_root / "utils" / "synthetic_data" / "multiturn" / "conversationalTestcases"
save_conversational_test_cases_to_json(
    conversational_test_cases, 
    str(output_dir),
    "rag_conversations"
)

# Option 2: Load from JSON file (uncomment to use)
# json_path = project_root / "utils" / "synthetic_data" / "multiturn_20251224_124204" / "multiturn_goldens_20251224_124204.json"
# if json_path.exists():
#     print("\n=== Simulating conversations from JSON file ===")
#     loaded_goldens = load_conversational_goldens_from_json(str(json_path))
#     print(f"Loaded {len(loaded_goldens)} conversational goldens from JSON")
#     conversational_test_cases_from_json = simulator.simulate(conversational_goldens=loaded_goldens[:3])  # Limit to first 3 for testing
#     print(f"\nGenerated {len(conversational_test_cases_from_json)} conversational test cases from JSON")
#     
#     # Save conversations from JSON to file
#     output_dir_json = project_root / "utils" / "synthetic_data" / f"conversations_from_json_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
#     save_conversational_test_cases_to_json(
#         conversational_test_cases_from_json,
#         str(output_dir_json),
#         "rag_conversations_from_json"
#     )