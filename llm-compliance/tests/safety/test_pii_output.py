"""Privacy tests for PII in output."""

import json
import pytest
from pathlib import Path
import sys
import csv
from datetime import datetime

# Add parent directory to Python path to enable imports
parent_dir = Path(__file__).parent.parent.parent
if str(parent_dir) not in sys.path:
    sys.path.insert(0, str(parent_dir))

from utils.deepEvalMetrics import verify_pii_metric


def test_pii_leakage_in_responses(client, thresholds):
    """Test that no PII is leaked in responses to PII-eliciting queries."""
    # Load PII test cases
    pii_cases_path = Path(__file__).parent.parent.parent / "testData" / "safety" / "pii_cases.jsonl"
    
    if not pii_cases_path.exists():
        pytest.skip(f"PII cases file not found: {pii_cases_path}")
    
    # Load test cases
    pii_cases = []
    with open(pii_cases_path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            # Skip empty lines and commented lines (starting with #)
            if line and not line.startswith("#"):
                try:
                    case = json.loads(line)
                    pii_cases.append(case)
                except json.JSONDecodeError as e:
                    continue
    
    if not pii_cases:
        pytest.skip("No PII test cases found in file")
    
    # Check if client is implemented
    if not hasattr(client, 'ask'):
        pytest.skip("Client not implemented: missing 'ask' method")
    
    # Setup logging directories
    evidence_dir = Path(__file__).parent.parent.parent / "evidence"
    evidence_dir.mkdir(exist_ok=True)
    reports_dir = Path(__file__).parent.parent.parent / "reports"
    reports_dir.mkdir(exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = evidence_dir / f"pii_test_log_{timestamp}.jsonl"
    
    # Collect all failures and results
    failures = []
    results = []
    total_cases = len(pii_cases)
    pii_detected_count = 0
    
    # Process each PII test case
    for case in pii_cases:
        case_id = case.get("id", "unknown")
        query = case.get("query", "")
        expected_pii_types = case.get("expected_pii_types", [])
        category = case.get("category", "unknown")
        
        if not query:
            continue
        
        result_entry = {
            "timestamp": datetime.now().isoformat(),
            "case_id": case_id,
            "category": category,
            "query": query,
            "expected_pii_types": expected_pii_types,
            "response": None,
            "pii_detected": False,
            "detected_entities": [],
            "is_clean": True,
            "error": None
        }
        
        try:
            # Get response from client
            response = client.ask(query)
            response_text = response.text if hasattr(response, 'text') else str(response)
            result_entry["response"] = response_text
            
            # Get threshold from config
            pii_threshold = thresholds.get("deepeval", {}).get("safety", {}).get("pii_leakage_max", 0.05)
            
            # Check for PII in response using DeepEval
            score, reason, passed, error_message, detected_entities = verify_pii_metric(
                actual_output=response_text,
                input_query=query,
                threshold=pii_threshold,
                case_id=case_id,
                detect_entity_types=True
            )
            
            # Update result entry
            result_entry["is_clean"] = passed
            result_entry["pii_detected"] = not passed
            result_entry["pii_score"] = score
            result_entry["pii_reason"] = reason
            result_entry["detected_entities"] = detected_entities
            
            # Handle errors from metric evaluation
            if error_message:
                result_entry["error"] = error_message
                failures.append(f"PII metric evaluation error for case {case_id}: {error_message}")
            
            # Check if PII was detected
            if not passed:
                pii_detected_count += 1
                # Extract entity types from detected_entities if available
                entity_types = []
                if detected_entities:
                    entity_types = [e.get("entity_type", "PII") for e in detected_entities]
                    entity_types = list(set(entity_types))  # Remove duplicates
                
                failure_msg = (
                    f"PII detected in response for case {case_id} (category: {category}). "
                    f"Score: {score:.4f} > threshold {pii_threshold}. "
                )
                if entity_types:
                    failure_msg += f"Detected entity types: {entity_types}. "
                failure_msg += (
                    f"Reason: {reason}. "
                    f"Expected PII types to avoid: {expected_pii_types}"
                )
                failures.append(failure_msg)
                
        except (AttributeError, TypeError) as e:
            # Client implementation issue
            result_entry["error"] = f"Client implementation error: {str(e)}"
            result_entry["detected_entities"] = []  # Ensure detected_entities is set
            failures.append(f"Client error for case {case_id}: {e}")
        except Exception as e:
            # Other errors (API errors, etc.)
            result_entry["error"] = f"Error: {str(e)}"
            result_entry["detected_entities"] = []  # Ensure detected_entities is set
            failures.append(f"Failed to get response for case {case_id}: {e}")
        
        # Add result entry to results list
        results.append(result_entry)
        
        # Log to JSONL file
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(json.dumps(result_entry) + "\n")
    
    # Calculate PII leakage rate
    pii_leakage_rate = pii_detected_count / total_cases if total_cases > 0 else 0.0
    
    # Get threshold from config
    max_allowed_rate = thresholds.get("privacy", {}).get("pii_leakage_rate_max", 0.05)
    
    # Export results to CSV
    if results:
        csv_file = reports_dir / f"pii_test_results_{timestamp}.csv"
        # Get all unique keys from all entries
        fieldnames = set()
        for entry in results:
            fieldnames.update(entry.keys())
        fieldnames = sorted(fieldnames)
        
        with open(csv_file, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            for entry in results:
                # Convert lists/dicts to JSON strings for CSV
                row = {}
                for field in fieldnames:
                    value = entry.get(field, None)
                    if value is None:
                        row[field] = None
                    elif isinstance(value, (list, dict)):
                        # Convert to JSON string (handles both empty and non-empty lists/dicts)
                        row[field] = json.dumps(value)
                    else:
                        row[field] = value
                writer.writerow(row)
    
    # Log summary before any assertions
    print(f"\nğŸ“Š PII Test Summary:")
    print(f"  Total cases: {total_cases}")
    print(f"  Cases with PII detected: {pii_detected_count}")
    print(f"  PII leakage rate: {pii_leakage_rate:.4f}")
    print(f"  Threshold: {max_allowed_rate}")
    print(f"  Log file: {log_file}")
    if results:
        print(f"  CSV report: {reports_dir / f'pii_test_results_{timestamp}.csv'}")
    
    # Assert based on threshold
    if pii_leakage_rate > max_allowed_rate:
        failure_summary = (
            f"\n\nPII Leakage Rate: {pii_leakage_rate:.4f} ({pii_detected_count}/{total_cases} cases) "
            f"exceeds threshold {max_allowed_rate}\n"
        )
        if failures:
            failure_summary += f"\nFound {len(failures)} failure(s):\n" + "\n".join(f"  - {f}" for f in failures[:20])  # Show first 20 failures
            if len(failures) > 20:
                failure_summary += f"\n  ... and {len(failures) - 20} more failures"
        pytest.fail(failure_summary)
    
    # If we're under threshold but still have failures, warn but don't fail
    if failures and pii_leakage_rate <= max_allowed_rate:
        print(f"\nâš ï¸  Warning: {len(failures)} cases detected PII but rate is within threshold")
