"""Conversation simulator utilities for single-turn and multi-turn conversations."""

from deepeval.test_case import Turn
from deepeval.simulator import ConversationSimulator
from deepeval.dataset import ConversationalGolden
from deepeval.test_case import ConversationalTestCase
from dotenv import load_dotenv
import sys
from pathlib import Path
import json
from datetime import datetime
import os
import yaml

load_dotenv()

# Add parent directory to Python path to enable imports
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# Import golden generators
from utils.generateSingleMultiTurnGoldens import generate_single_turn_goldens, generate_multiturn_goldens, save_goldens_to_json


def load_config():
    """Load configuration from syntheticData_config.yaml"""
    config_path = project_root / "testData" / "config" / "syntheticData_config.yaml"
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config.get('syntheticData_config', {})

# Load config
_config = load_config()


def load_conversational_goldens_from_json(json_path: str):
    """
    Load ConversationalGolden objects from a JSON file generated by the synthesizer.
    
    Args:
        json_path: Path to the JSON file containing conversational goldens
    
    Returns:
        List of ConversationalGolden objects
    """
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    goldens = []
    for item in data:
        golden = ConversationalGolden(
            scenario=item.get('scenario', ''),
            expected_outcome=item.get('expected_outcome', ''),
            user_description=item.get('user_description'),
            context=item.get('context', []),
        )
        goldens.append(golden)
    
    return goldens


def save_conversational_test_cases_to_json(test_cases, output_dir: str, filename_prefix: str = "conversational_test_cases"):
    """
    Save ConversationalTestCase objects to a JSON file.
    
    Args:
        test_cases: List of ConversationalTestCase objects
        output_dir: Directory where to save the JSON file
        filename_prefix: Prefix for the filename
    
    Returns:
        Path to the saved JSON file
    """
    # Create directory if it doesn't exist
    os.makedirs(output_dir, exist_ok=True)
    
    # Convert test cases to dictionaries
    test_cases_data = []
    for test_case in test_cases:
        test_case_dict = {
            "turns": [
                {
                    "role": turn.role,
                    "content": turn.content,
                    **({"retrieval_context": turn.retrieval_context} if hasattr(turn, 'retrieval_context') and turn.retrieval_context else {})
                }
                for turn in test_case.turns
            ]
        }
        
        # Add additional attributes if they exist
        if hasattr(test_case, 'scenario'):
            test_case_dict["scenario"] = test_case.scenario
        if hasattr(test_case, 'expected_outcome'):
            test_case_dict["expected_outcome"] = test_case.expected_outcome
        if hasattr(test_case, 'user_description'):
            test_case_dict["user_description"] = test_case.user_description
        if hasattr(test_case, 'context'):
            test_case_dict["context"] = test_case.context
        
        test_cases_data.append(test_case_dict)
    
    # Create filename with timestamp
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"{filename_prefix}_{timestamp}.json"
    filepath = os.path.join(output_dir, filename)
    
    # Save to JSON file
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(test_cases_data, f, indent=2, ensure_ascii=False)
    
    print(f"\n‚úÖ Saved {len(test_cases)} conversational test cases to: {filepath}")
    return filepath


def singleturnconversationsimulator(
    model_callback=None,
    output_dir: str = None,
    filename_prefix: str = "singleturn_conversations"
):
    """
    Generate single-turn goldens using existing generator and optionally simulate them.
    
    Note: Single-turn goldens are typically not simulated as they are single Q&A pairs.
    This function uses generate_single_turn_goldens() from dataUtilities.py.
    
    Args:
        model_callback: Optional callback function (not typically used for single-turn).
        output_dir: Directory to save output. If None, uses default from dataUtilities.
        filename_prefix: Prefix for output filename (not used, dataUtilities handles saving)
    
    Returns:
        List of generated goldens (Golden objects)
    """
    print("üîÑ Generating single-turn goldens using dataUtilities.generate_single_turn_goldens()...")
    
    # Use existing generator from dataUtilities
    goldens = generate_single_turn_goldens()
    
    print(f"\n‚úÖ Generated {len(goldens)} single-turn golden test cases")
    
    # Note: generate_single_turn_goldens() already saves the goldens
    # model_callback is not used for single-turn as they are not conversational
    
    return goldens


def multiturnconversationsimulator(
    model_callback=None,
    conversational_goldens=None,
    json_path=None,
    output_dir: str = None,
    filename_prefix: str = "multiturn_conversations"
):
    """
    Generate and/or simulate multi-turn conversations.
    
    Uses generate_multiturn_goldens() from dataUtilities.py for generation.
    Adds simulation capability using ConversationSimulator.
    
    Args:
        model_callback: Callback function for simulating conversations. 
                       If None, only generates goldens without simulation.
                       Required for simulation. Can import from wrapModelForSyntheticData or wrapRAGModelForSyntheticData.
        conversational_goldens: Optional list of ConversationalGolden objects to simulate.
                               If provided, skips generation and uses these directly.
        json_path: Optional path to JSON file containing conversational goldens to simulate.
                   If provided, loads goldens from file instead of generating.
        output_dir: Directory to save simulated conversations. If None, uses default.
        filename_prefix: Prefix for output filename (only used for simulated conversations)
    
    Returns:
        List of ConversationalTestCase objects (if simulated) or ConversationalGolden objects (if only generated)
    """
    # Determine source of goldens
    if conversational_goldens:
        # Use provided goldens
        goldens_to_simulate = conversational_goldens
        print(f"üìã Using {len(goldens_to_simulate)} provided conversational goldens")
    elif json_path:
        # Load from JSON file
        print(f"üìÇ Loading conversational goldens from: {json_path}")
        goldens_to_simulate = load_conversational_goldens_from_json(json_path)
        print(f"‚úÖ Loaded {len(goldens_to_simulate)} conversational goldens")
    else:
        # Generate from documents using existing function
        print("üîÑ Generating multi-turn goldens using dataUtilities.generate_multiturn_goldens()...")
        goldens_to_simulate = generate_multiturn_goldens()
        print(f"‚úÖ Generated {len(goldens_to_simulate)} conversational golden test cases")
    
    # Simulate conversations if model_callback is provided
    if model_callback:
        print(f"\nüîÑ Simulating {len(goldens_to_simulate)} conversations...")
        simulator = ConversationSimulator(model_callback=model_callback)
        
        try:
            test_cases = simulator.simulate(conversational_goldens=goldens_to_simulate)
            print(f"‚úÖ Successfully simulated {len(test_cases)} conversations")
            
            # Display simulated conversations
            for i, test_case in enumerate(test_cases, 1):
                print(f"\n--- Simulated Test Case {i} ---")
                print(f"Turns: {len(test_case.turns)}")
                for j, turn in enumerate(test_case.turns, 1):
                    print(f"  Turn {j} ({turn.role}): {turn.content[:100]}..." if len(turn.content) > 100 else f"  Turn {j} ({turn.role}): {turn.content}")
            
            # Save simulated conversations
            # Get directory from config if not provided
            if output_dir is None:
                multiturn_config = _config.get('multiturn', {})
                test_cases_config = multiturn_config.get('test_cases', {})
                output_dir = project_root / test_cases_config.get('directory', 'testData/synthetic_data/multiturn/conversationalTestCases')
            else:
                output_dir = Path(output_dir)
            
            filepath = save_conversational_test_cases_to_json(
                test_cases,
                str(output_dir),
                filename_prefix
            )
            
            return test_cases
        except Exception as e:
            print(f"‚ùå Error during simulation: {e}")
            print("‚ö†Ô∏è  Returning goldens without simulation")
            return goldens_to_simulate
    else:
        # No simulation, just return goldens (already saved by generate_multiturn_goldens)
        print("\n‚ö†Ô∏è  No model_callback provided. Skipping simulation.")
        print("   To simulate conversations, provide a model_callback function.")
        print("   Example: from utils.wrapRAGModelForSyntheticData import model_callback")
        print("   Goldens have already been saved by generate_multiturn_goldens()")
        
        return goldens_to_simulate


def newConversationFromJsonAndSimulate(json_path: str, model_callback=None, output_dir: str = None, filename_prefix: str = "conversations_from_json"):
    """
    Load conversational goldens from a JSON file and simulate conversations.
    
    This method calls multiturnconversationsimulator() with the json_path parameter.
    
    Args:
        json_path: Path to JSON file containing conversational goldens
        model_callback: Callback function for simulating conversations. 
                       Required for simulation. Can import from wrapModelForSyntheticData or wrapRAGModelForSyntheticData.
        output_dir: Directory to save simulated conversations. If None, uses default.
        filename_prefix: Prefix for output filename
    
    Returns:
        List of ConversationalTestCase objects (if simulated) or ConversationalGolden objects (if model_callback not provided)
    """
    if not model_callback:
        raise ValueError("model_callback is required for simulation. Please provide a model_callback function.")
    
    print(f"üìÇ Loading conversational goldens from JSON and simulating...")
    return multiturnconversationsimulator(
        model_callback=model_callback,
        json_path=json_path,
        output_dir=output_dir,
        filename_prefix=filename_prefix
    )


def newConversationFromGoldenListObject(goldens: list[ConversationalGolden], model_callback=None, output_dir: str = None, filename_prefix: str = "conversations_from_goldens"):
    """
    Simulate conversations from a list of ConversationalGolden objects.
    
    This method calls multiturnconversationsimulator() with the conversational_goldens parameter.
    
    Args:
        goldens: List of ConversationalGolden objects to simulate
        model_callback: Callback function for simulating conversations. 
                       Required for simulation. Can import from wrapModelForSyntheticData or wrapRAGModelForSyntheticData.
        output_dir: Directory to save simulated conversations. If None, uses default.
        filename_prefix: Prefix for output filename
    
    Returns:
        List of ConversationalTestCase objects (if simulated) or ConversationalGolden objects (if model_callback not provided)
    """
    if not model_callback:
        raise ValueError("model_callback is required for simulation. Please provide a model_callback function.")
    
    if not goldens or len(goldens) == 0:
        raise ValueError("goldens list cannot be empty. Please provide at least one ConversationalGolden object.")
    
    print(f"üìã Using {len(goldens)} provided conversational goldens and simulating...")
    return multiturnconversationsimulator(
        model_callback=model_callback,
        conversational_goldens=goldens,
        output_dir=output_dir,
        filename_prefix=filename_prefix
    )


def newConversationFromScratchCreateGoldensAndSimulate(model_callback=None, output_dir: str = None, filename_prefix: str = "conversations_from_scratch"):
    """
    Generate conversational goldens from scratch and simulate conversations.
    
    This method calls multiturnconversationsimulator() without json_path or conversational_goldens,
    which will trigger generation from documents using generate_multiturn_goldens().
    
    Args:
        model_callback: Callback function for simulating conversations. 
                       Required for simulation. Can import from wrapModelForSyntheticData or wrapRAGModelForSyntheticData.
        output_dir: Directory to save simulated conversations. If None, uses default.
        filename_prefix: Prefix for output filename
    
    Returns:
        List of ConversationalTestCase objects (if simulated) or ConversationalGolden objects (if model_callback not provided)
    """
    if not model_callback:
        raise ValueError("model_callback is required for simulation. Please provide a model_callback function.")
    
    print("üîÑ Generating multi-turn goldens from scratch and simulating...")
    return multiturnconversationsimulator(
        model_callback=model_callback,
        json_path=None,
        conversational_goldens=None,
        output_dir=output_dir,
        filename_prefix=filename_prefix
    )


if __name__ == "__main__":
    # Example usage
    
    # Option 1: Generate single-turn goldens
    print("=" * 80)
    print("Single-Turn Conversation Simulator")
    print("=" * 80)
    # singleturnconversationsimulator()
    
    # Option 2: Generate multi-turn goldens (without simulation)
    print("\n" + "=" * 80)
    print("Multi-Turn Conversation Simulator (Generate Only)")
    print("=" * 80)
    # multiturnconversationsimulator()
    
    # Option 3: Generate and simulate multi-turn conversations
    print("\n" + "=" * 80)
    print("Multi-Turn Conversation Simulator (With Simulation)")
    print("=" * 80)
    try:
        from utils.wrapRAGModelForSyntheticData import model_callback
        #newConversationFromScratchCreateGoldensAndSimulate(model_callback=model_callback)
        newConversationFromJsonAndSimulate(json_path=project_root / "testData" / "synthetic_data" / "multiturn" / "conversationalGoldens" / "rag_conversations_knowledge_retention.json", model_callback=model_callback)
    except ImportError:
        print("‚ö†Ô∏è  Could not import model_callback. Skipping simulation example.")
        print("   To use simulation, ensure wrapRAGModelForSyntheticData.py exists and has model_callback function.")

